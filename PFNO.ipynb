{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "SEED = 42 # Use same seed for replicable data generation\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Import data loader and loss function\n",
    "from FNO1D_utils import (\n",
    "    data_loader,\n",
    "    relative_min_max,\n",
    "    normal_RMSE,\n",
    ")\n",
    "# Set path to data set\n",
    "path = '/mimer/NOBACKUP/groups/ml_flame_storage/Max_1D/Data/1D200.h5'\n",
    "from FNO1D import FNO1d\n",
    "\n",
    "train_loader, test_loader, inp_max, inp_min, out_max, out_min, x_max, x_min, y_max, y_min = data_loader(path, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mass loss tensor(265.4766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy loss tensor(17491.6777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "phys_loss tensor(0., device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch [1/2500] - Train Loss: 5.862295 - Test Loss: 3.076812 - Test Relative Error: 102.560406%\n",
      "  Train:  Temperature Rel: 372.515458% | Pressure Rel: 142.531430% | Velocity Rel: 71.182588% | \n",
      "  Test:   Temperature Rel: 160.059479% | Pressure Rel: 98.685978% | Velocity Rel: 48.935768% | \n",
      "\n",
      "mass loss tensor(241.5526, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy loss tensor(-1102.5735, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "phys_loss tensor(0.1686, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch [51/2500] - Train Loss: 1.647998 - Test Loss: 2.020134 - Test Relative Error: 67.337797%\n",
      "  Train:  Temperature Rel: 72.524607% | Pressure Rel: 51.360237% | Velocity Rel: 40.914946% | \n",
      "  Test:   Temperature Rel: 101.414383% | Pressure Rel: 59.198193% | Velocity Rel: 41.400805% | \n",
      "\n",
      "mass loss tensor(-29.2660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy loss tensor(-652.1562, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "phys_loss tensor(0.0418, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch [101/2500] - Train Loss: 1.051930 - Test Loss: 0.661824 - Test Relative Error: 22.060806%\n",
      "  Train:  Temperature Rel: 64.655690% | Pressure Rel: 20.587457% | Velocity Rel: 19.949809% | \n",
      "  Test:   Temperature Rel: 27.865646% | Pressure Rel: 19.690320% | Velocity Rel: 18.626449% | \n",
      "\n",
      "mass loss tensor(-28.7175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy loss tensor(187.2320, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "phys_loss tensor(0.0709, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch [151/2500] - Train Loss: 0.557234 - Test Loss: 0.568854 - Test Relative Error: 18.961792%\n",
      "  Train:  Temperature Rel: 25.295094% | Pressure Rel: 14.348498% | Velocity Rel: 16.079852% | \n",
      "  Test:   Temperature Rel: 24.177036% | Pressure Rel: 16.379283% | Velocity Rel: 16.329055% | \n",
      "\n",
      "mass loss tensor(-16.4675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy loss tensor(-1690.9579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "phys_loss tensor(0.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch [201/2500] - Train Loss: 0.630771 - Test Loss: 0.604012 - Test Relative Error: 20.133737%\n",
      "  Train:  Temperature Rel: 28.766058% | Pressure Rel: 19.276834% | Velocity Rel: 15.034257% | \n",
      "  Test:   Temperature Rel: 19.279265% | Pressure Rel: 24.102518% | Velocity Rel: 17.019425% | \n",
      "\n",
      "mass loss tensor(-28.7267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy loss tensor(2456.3689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "phys_loss tensor(0.0584, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch [251/2500] - Train Loss: 0.432094 - Test Loss: 0.542148 - Test Relative Error: 18.071615%\n",
      "  Train:  Temperature Rel: 18.482842% | Pressure Rel: 12.575434% | Velocity Rel: 12.151116% | \n",
      "  Test:   Temperature Rel: 19.098793% | Pressure Rel: 20.171670% | Velocity Rel: 14.944382% | \n",
      "\n",
      "mass loss tensor(-20.6675, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "energy loss tensor(758.3781, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "phys_loss tensor(0.0607, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "Epoch [301/2500] - Train Loss: 0.366775 - Test Loss: 0.410719 - Test Relative Error: 13.690629%\n",
      "  Train:  Temperature Rel: 14.601714% | Pressure Rel: 11.366333% | Velocity Rel: 10.709414% | \n",
      "  Test:   Temperature Rel: 12.454215% | Pressure Rel: 14.673573% | Velocity Rel: 13.944100% | \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m bc, target_field, x, y \u001b[38;5;241m=\u001b[39m bc\u001b[38;5;241m.\u001b[39mto(device), target_field\u001b[38;5;241m.\u001b[39mto(device), x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     60\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 61\u001b[0m pred_field \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m pred_field_real\u001b[38;5;241m=\u001b[39m pred_field\u001b[38;5;241m*\u001b[39m(out_max_torch\u001b[38;5;241m-\u001b[39mout_min_torch) \u001b[38;5;241m+\u001b[39m out_min_torch\n\u001b[1;32m     63\u001b[0m target_field_real \u001b[38;5;241m=\u001b[39m target_field\u001b[38;5;241m*\u001b[39m(out_max_torch\u001b[38;5;241m-\u001b[39mout_min_torch) \u001b[38;5;241m+\u001b[39m out_min_torch\n",
      "File \u001b[0;32m/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mimer/NOBACKUP/groups/ml_flame_storage/Max_1D/FNO1D/Final/FNO1D.py:144\u001b[0m, in \u001b[0;36mFNO1d.forward\u001b[0;34m(self, bc, x, y)\u001b[0m\n\u001b[1;32m    142\u001b[0m temp_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtemp_decoder(x)           \u001b[38;5;66;03m# (B, N_x, 1)\u001b[39;00m\n\u001b[1;32m    143\u001b[0m pressure_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpressure_decoder(x) \u001b[38;5;66;03m# (B, N_x, 1)\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m vel_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvel_decoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m           \u001b[38;5;66;03m# (B, N_x, 1)\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;66;03m# Concatenate outputs back into single tensor: [T, P, u]\u001b[39;00m\n\u001b[1;32m    146\u001b[0m final_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([temp_out, pressure_out, vel_out], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (B, N_x, 3)\u001b[39;00m\n",
      "File \u001b[0;32m/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/apps/Arch/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define physical constants\n",
    "C_p = 1000\n",
    "gamma = 1.4\n",
    "C_v = C_p/gamma\n",
    "R = C_p - C_v\n",
    "# --------------------------------------------------------------------------------\n",
    "# 5) Training \n",
    "# --------------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Instantiate the FNO and training parameters\n",
    "    # ------------------------------------------------\n",
    "    model = FNO1d(modes=16, width=32, hidden_mlp=128, N_x=128, N_fourier_layers=4).to(device)\n",
    "    phys_w_max      = 10     # the weight you want to end up with\n",
    "    warmup_epochs   = 2000\n",
    "    epochs = 2500\n",
    "    learning_rate = 1e-2\n",
    "    step_size = 100\n",
    "    gamma = 0.7\n",
    "    weight_decay = 1e-4\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "    out_max_torch = torch.from_numpy(out_max).to(device)\n",
    "    out_min_torch = torch.from_numpy(out_min).to(device)\n",
    "    \n",
    "    # Define loss and error evaluation function\n",
    "    criterion_loss = relative_min_max\n",
    "    criterion_eval = relative_min_max\n",
    "   \n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # Preallocate losses and relative errors\n",
    "    # ------------------------------------------------\n",
    "    train_losses = []\n",
    "    phys_losses = []\n",
    "    test_losses = []\n",
    "    test_rel_list = []\n",
    "    test_rel_pressure_list = []\n",
    "    test_rel_velocity_list = []\n",
    "    test_rel_temperature_list = []\n",
    "    rel_final_batch = []\n",
    "    rel_err_sum = 0\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # Training loop\n",
    "    # ------------------------------------------------\n",
    "    for epoch in range(epochs):\n",
    "        phys_w = phys_w_max * min(1.0, epoch / warmup_epochs)\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        total_phys_loss = 0.0\n",
    "        train_rel_pressure = 0.0\n",
    "        train_rel_velocity = 0.0\n",
    "        train_rel_temperature = 0.0\n",
    "        for bc, target_field, x, y in train_loader:\n",
    "            bc, target_field, x, y = bc.to(device), target_field.to(device), x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred_field = model(bc, x, y)\n",
    "            pred_field_real= pred_field*(out_max_torch-out_min_torch) + out_min_torch\n",
    "            target_field_real = target_field*(out_max_torch-out_min_torch) + out_min_torch\n",
    "\n",
    "            # Renormalize physical units\n",
    "            real_x = x*(x_max-x_min) + x_min\n",
    "            real_y = y*(y_max-y_min) + y_min\n",
    "            real_temp = pred_field_real[:,:,0]\n",
    "            real_press = pred_field_real[:,:,1]\n",
    "            real_vel = pred_field_real[:,:,2]\n",
    "\n",
    "            rho = real_press/(R*real_temp)\n",
    "            mass = rho * real_vel*y\n",
    "            energy = C_p*real_temp + (real_vel**2)/2\n",
    "\n",
    "            mass_residual = mass[:,-1] - mass[:,0]\n",
    "            mass_mean = torch.mean(mass)\n",
    "            energy_residual = (energy[:, -1] - energy[:, 0])\n",
    "            energy_mean = torch.mean(energy)\n",
    "\n",
    "            mass_residual_norm = mass_residual/mass_mean\n",
    "            energy_residual_norm = energy_residual/energy_mean\n",
    "\n",
    "            loss_phys = phys_w*(torch.sqrt(torch.mean(mass_residual_norm**2)) + torch.sqrt(torch.mean(energy_residual_norm**2)))\n",
    "\n",
    "            # Training loss\n",
    "            loss_vec = criterion_loss(pred_field, target_field)\n",
    "            train_loss = (loss_vec[0] + loss_vec[1] + loss_vec[2])\n",
    "            loss = train_loss + loss_phys\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0) # Works good for small datasets\n",
    "            optimizer.step()\n",
    "            total_train_loss += train_loss.item()\n",
    "            total_phys_loss += loss_phys.item()\n",
    "\n",
    "            # Batch wise relative errors\n",
    "            train_eval_error = criterion_eval(pred_field, target_field)*100\n",
    "            batch_train_rel_temperature = train_eval_error[0]\n",
    "            batch_train_rel_pressure = train_eval_error[1]\n",
    "            batch_train_rel_velocity = train_eval_error[2]\n",
    "            train_rel_pressure += batch_train_rel_pressure.item()\n",
    "            train_rel_velocity += batch_train_rel_velocity.item()\n",
    "            train_rel_temperature += batch_train_rel_temperature.item()\n",
    "            \n",
    "        # Average over batchwise losses and errors    \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        avg_phys_loss = total_phys_loss/len(train_loader)\n",
    "        avg_train_rel_pressure = train_rel_pressure / len(train_loader)\n",
    "        avg_train_rel_velocity = train_rel_velocity / len(train_loader)\n",
    "        avg_train_rel_temperature = train_rel_temperature / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        phys_losses.append(avg_phys_loss)\n",
    "        \n",
    "        # ------------------------------------------------\n",
    "        # Evaluate model on test data\n",
    "        # ------------------------------------------------\n",
    "        model.eval()\n",
    "        total_test_loss = 0.0\n",
    "        test_rel_error = 0.0\n",
    "        test_rel_pressure = 0.0\n",
    "        test_rel_velocity = 0.0\n",
    "        test_rel_temperature = 0.0\n",
    "        with torch.no_grad():\n",
    "            for bc, target_field, x, y in test_loader:\n",
    "                bc, target_field, x, y = bc.to(device), target_field.to(device), x.to(device), y.to(device)\n",
    "                pred_field = model(bc, x, y)\n",
    "\n",
    "                # Test Loss\n",
    "                loss_vec = criterion_eval(pred_field, target_field)\n",
    "                loss = (loss_vec[0] + loss_vec[1] + loss_vec[2])\n",
    "                total_test_loss += loss.item()\n",
    "\n",
    "                batch_rel_error = torch.mean(loss_vec)*100\n",
    "                test_rel_error += batch_rel_error.item()\n",
    "\n",
    "                # Batch wise relative errors\n",
    "                test_eval_error = criterion_eval(pred_field, target_field)*100\n",
    "                batch_rel_temperature = test_eval_error[0]\n",
    "                batch_rel_pressure = test_eval_error[1]\n",
    "                batch_rel_velocity = test_eval_error[2]\n",
    "\n",
    "                test_rel_temperature += batch_rel_temperature.item()\n",
    "                test_rel_pressure += batch_rel_pressure.item()\n",
    "                test_rel_velocity += batch_rel_velocity.item()\n",
    "                \n",
    "                # Individual relative error of each sample\n",
    "                if epoch == epochs-1:\n",
    "                    num = (pred_field-target_field)**2\n",
    "                    denom = (torch.amax(target_field, dim=[1], keepdim=True) - torch.amin(target_field, dim=[1], keepdim=True))**2\n",
    "                    rel_err = torch.mean(num/denom, dim=[1])\n",
    "                    rel_err = torch.sqrt(rel_err)*100\n",
    "                    rel_final_batch.extend(rel_err.cpu().tolist())\n",
    "\n",
    "\n",
    "        # Average batchwise errors\n",
    "        avg_test_loss = total_test_loss / len(test_loader)\n",
    "        avg_test_rel = test_rel_error / len(test_loader)\n",
    "        avg_rel_pressure = test_rel_pressure / len(test_loader)\n",
    "        avg_rel_velocity = test_rel_velocity / len(test_loader)\n",
    "        avg_rel_temperature = test_rel_temperature / len(test_loader)\n",
    "        test_losses.append(avg_test_loss)\n",
    "\n",
    "        # Store test relative errors for plotting\n",
    "        test_rel_list.append(avg_test_rel)\n",
    "        test_rel_temperature_list.append(avg_rel_temperature)\n",
    "        test_rel_pressure_list.append(avg_rel_pressure)\n",
    "        test_rel_velocity_list.append(avg_rel_velocity)\n",
    "        \n",
    "        if epoch % 50 == 0 or epoch == epochs - 1:\n",
    "            print(\"mass loss\", torch.mean(mass_residual))\n",
    "            print(\"energy loss\", torch.mean(energy_residual))\n",
    "            print(\"phys_loss\", loss_phys)\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] - Train Loss: {avg_train_loss:.6f} - Test Loss: {avg_test_loss:.6f} - Test Relative Error: {avg_test_rel:.6f}%\")\n",
    "            print(\n",
    "                f\"  Train:  Temperature Rel: {avg_train_rel_temperature:.6f}% | \"\n",
    "                f\"Pressure Rel: {avg_train_rel_pressure:.6f}% | \"\n",
    "                f\"Velocity Rel: {avg_train_rel_velocity:.6f}% | \"\n",
    "                \n",
    "            )\n",
    "            print(\n",
    "                f\"  Test:   Temperature Rel: {avg_rel_temperature:.6f}% | \"\n",
    "                f\"Pressure Rel: {avg_rel_pressure:.6f}% | \"\n",
    "                f\"Velocity Rel: {avg_rel_velocity:.6f}% | \"\n",
    "                \n",
    "            )\n",
    "            print()\n",
    "        scheduler.step()\n",
    "        \n",
    "    print(\"Training complete!\")\n",
    "    # ------------------------------------------------\n",
    "    # Plot losses vs Epoch\n",
    "    # ------------------------------------------------\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, epochs+1), train_losses, label=\"Train Loss\")\n",
    "    plt.plot(range(1, epochs+1), test_losses, label=\"Test Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Log-Loss\")\n",
    "    plt.yscale('log')\n",
    "    plt.title(\"Loss vs Epoch\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), '1DPFNO.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
